{"original_code": "def load_celery_current_and_parent_ids(\n    header_key: str = \"CELERY_PARENT_ID\",\n    generator: Callable[[], str] = uuid_hex_generator,\n    use_internal_celery_task_id: bool = False,\n) -> None:\n    \"\"\"\n    Configure Celery event hooks for generating tracing IDs with depth.\n\n    This is not called automatically by the middleware.\n    To use this, users should manually run it during startup.\n    \"\"\"\n    from asgi_correlation_id.context import celery_current_id, celery_parent_id\n\n    @before_task_publish.connect(weak=False)\n    def publish_task_from_worker_or_request(\n        headers: Dict[str, str], **kwargs: Any\n    ) -> None:\n        \"\"\"\n        Transfer the current ID to the next Celery worker, by adding\n        it as a header.\n\n        This way we're able to tell which process spawned the next task.\n        \"\"\"\n        current = celery_current_id.get()\n        if current:\n            headers[header_key] = current\n\n    @task_prerun.connect(weak=False)\n    def worker_prerun(task_id: str, task: \"Task\", **kwargs: Any) -> None:\n        \"\"\"\n        Set current ID, and parent ID if it exists.\n        \"\"\"\n        parent_id = task.request.get(header_key)\n        if parent_id:\n            celery_parent_id.set(parent_id)\n\n        celery_id = task_id if use_internal_celery_task_id else generator()\n        celery_current_id.set(celery_id)\n\n    @task_postrun.connect(weak=False)\n    def clean_up(**kwargs: Any) -> None:\n        \"\"\"\n        Clear context vars, to avoid re-using values in the next task.\n        \"\"\"\n        celery_current_id.set(None)\n        celery_parent_id.set(None)"}