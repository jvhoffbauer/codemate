{"original_code": "@cached(cache=TTLCache(maxsize=1, ttl=1800))\nasync def get_locations():\n    \"\"\"\n    Returns a list containing parsed NYT data by US county. The data is cached for 1 hour.\n\n    :returns: The complete data for US Counties.\n    :rtype: dict\n    \"\"\"\n    data_id = \"nyt.locations\"\n    # Request the data.\n    LOGGER.info(f\"{data_id} Requesting data...\")\n    # check shared cache\n    cache_results = await check_cache(data_id)\n    if cache_results:\n        LOGGER.info(f\"{data_id} using shared cache results\")\n        locations = cache_results\n    else:\n        LOGGER.info(f\"{data_id} shared cache empty\")\n        async with httputils.CLIENT_SESSION.get(BASE_URL) as response:\n            text = await response.text()\n\n        LOGGER.debug(f\"{data_id} Data received\")\n\n        # Parse the CSV.\n        data = list(csv.DictReader(text.splitlines()))\n        LOGGER.debug(f\"{data_id} CSV parsed\")\n\n        # Group together locations (NYT data ordered by dates not location).\n        grouped_locations = get_grouped_locations_dict(data)\n\n        # The normalized locations.\n        locations = []\n\n        for idx, (county_state, histories) in enumerate(grouped_locations.items()):\n            # Make location history for confirmed and deaths from dates.\n            # List is tuples of (date, amount) in order of increasing dates.\n            confirmed_list = histories[\"confirmed\"]\n            confirmed_history = {\n                date: int(amount or 0) for date, amount in confirmed_list\n            }\n\n            deaths_list = histories[\"deaths\"]\n            deaths_history = {date: int(amount or 0) for date, amount in deaths_list}\n\n            # Normalize the item and append to locations.\n            locations.append(\n                NYTLocation(\n                    id=idx,\n                    state=county_state[1],\n                    county=county_state[0],\n                    coordinates=Coordinates(\n                        None, None\n                    ),  # NYT does not provide coordinates\n                    last_updated=datetime.utcnow().isoformat()\n                    + \"Z\",  # since last request\n                    timelines={\n                        \"confirmed\": Timeline(\n                            timeline={\n                                datetime.strptime(date, \"%Y-%m-%d\").isoformat()\n                                + \"Z\": amount\n                                for date, amount in confirmed_history.items()\n                            }\n                        ),\n                        \"deaths\": Timeline(\n                            timeline={\n                                datetime.strptime(date, \"%Y-%m-%d\").isoformat()\n                                + \"Z\": amount\n                                for date, amount in deaths_history.items()\n                            }\n                        ),\n                        \"recovered\": Timeline(),\n                    },\n                )\n            )\n        LOGGER.info(f\"{data_id} Data normalized\")\n        # save the results to distributed cache\n        # TODO: fix json serialization\n        try:\n            await load_cache(data_id, locations)\n        except TypeError as type_err:\n            LOGGER.error(type_err)\n\n    return locations"}